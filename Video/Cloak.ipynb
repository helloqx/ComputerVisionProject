{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invisibility Cloak Special Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_VIDEO = \"./Cloak.mov\"\n",
    "PATH_OUTPUT = \"output.avi\"\n",
    "PATH_BG = \"bg.jpg\"\n",
    "PATH_BG_2 = \"bg2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_show_scenes = False\n",
    "is_save_video = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_video(path=PATH_VIDEO):\n",
    "    cap = cv2.VideoCapture(PATH_VIDEO)\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened(): \n",
    "        print(\"Error opening video stream\")\n",
    "    \n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_video_writer(video):\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    return cv2.VideoWriter(PATH_OUTPUT, fourcc, video.get(cv2.CAP_PROP_FPS), \n",
    "                         (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_single_frame(video, output_path, frame_num=0):\n",
    "    '''\n",
    "    Saves a single frame from video as an image at output_path.\n",
    "    '''\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imwrite(output_path, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skip_to_frame(video, frame_num):\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get background shot\n",
    "cap = open_video()\n",
    "get_single_frame(cap, \"bgasd.jpg\", 502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg = cv2.imread(PATH_BG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_bgr_to_hsv(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "    return hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_frame(hsv, lower_color, upper_color):\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_frame(frame):\n",
    "    frame_inv = cv2.bitwise_not(frame)\n",
    "    return frame_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_frame(frame, mask):\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def or_frames(frame1, frame2):\n",
    "    return cv2.bitwise_or(frame1, frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_frame(frameNum, frame):\n",
    "    '''\n",
    "        Scene:\n",
    "        0   - 135    walking in\n",
    "        135 - 479    unfolding\n",
    "        480 - 521    cloth over head\n",
    "        522 - 630    first wear\n",
    "        631 - 655    pulling over\n",
    "        656+         completely covered\n",
    "    '''\n",
    "    \n",
    "    if frameNum <= 479:\n",
    "        return cloth_texture(frame)\n",
    "    elif frameNum <= 521:\n",
    "        return protect_hair(frame)\n",
    "    elif frameNum <= 630:\n",
    "        return cloth_texture(frame)\n",
    "    elif frameNum <= 655:\n",
    "        return protect_hair(frame)\n",
    "    else:\n",
    "        return cloth_texture(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def protect_hair(frame):\n",
    "        \n",
    "        green_dk_low = np.array([0, 115, 70], np.uint8)\n",
    "        green_dk_upp = np.array([80, 255, 150], np.uint8)\n",
    "        green_nm_low = np.array([0, 115, 150], np.uint8)\n",
    "        green_nm_upp = np.array([80, 255, 200], np.uint8)\n",
    "        green_bt_low = np.array([0, 115, 200], np.uint8)\n",
    "        green_bt_upp = np.array([80, 255, 255], np.uint8)\n",
    "\n",
    "        head_low = np.array([75, 0, 0], np.uint8)\n",
    "        head_upp = np.array([100, 255, 255], np.uint8)\n",
    "        hair_low = np.array([0, 0, 0], np.uint8)\n",
    "        hair_upp = np.array([180, 255, 77], np.uint8)\n",
    "\n",
    "        hsv = convert_bgr_to_hsv(frame)\n",
    "        mask_dk = threshold_frame(hsv, green_dk_low, green_dk_upp)\n",
    "        mask_nm = threshold_frame(hsv, green_nm_low, green_nm_upp)\n",
    "        mask_bt = threshold_frame(hsv, green_bt_low, green_bt_upp)\n",
    "        \n",
    "        mask_head = threshold_frame(hsv, head_low, head_upp)\n",
    "        mask_hair = threshold_frame(hsv, hair_low, hair_upp)\n",
    "        \n",
    "        mask = or_frames(or_frames(mask_bt, mask_nm), mask_dk)\n",
    "        \n",
    "        kernel_ones = np.ones((3,3),np.uint8)\n",
    "        kernel_gauss = cv2.getGaussianKernel(5, 3)\n",
    "        \n",
    "        mask_dil = cv2.erode(mask, kernel_ones, iterations = 1)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_ones, iterations = 5)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_gauss, iterations = 5)\n",
    "        \n",
    "        mask_border = cv2.bitwise_and(invert_frame(mask), mask_dil)\n",
    "        mask_border = cv2.GaussianBlur(mask_border, (5,5), 0)\n",
    "        \n",
    "        \n",
    "        mask_border = cv2.min(invert_frame(mask_hair), mask_border)\n",
    "        mask_inv = invert_frame(mask_dil)\n",
    "        \n",
    "        mask_head = cv2.bitwise_and(mask_dil, mask_head)\n",
    "        \n",
    "        mask_inv = cv2.max(mask_inv, mask_head)\n",
    "        \n",
    "        og = mask_frame(frame, mask_inv)\n",
    "        \n",
    "        # Get \"see-through\" background\n",
    "        bg_bt = mask_frame(bg, mask_bt)\n",
    "        bg_nm = mask_frame(bg, mask_nm)\n",
    "        bg_dk = mask_frame(bg, mask_dk)\n",
    "        bg_border = mask_frame(bg, mask_border)\n",
    "        \n",
    "        background = mask_frame(bg, mask)\n",
    "        \n",
    "        alpha_border = 0.93\n",
    "        alpha_nm = 0.9\n",
    "        \n",
    "        alpha_bt = 0.87\n",
    "        alpha_d = 0.85\n",
    "        \n",
    "        cv2.addWeighted(bg_border, alpha_border, og, 0, 0.0, bg_border);\n",
    "        cv2.addWeighted(bg_nm, alpha_nm, og, 0, 0.0, bg_nm);\n",
    "        cv2.addWeighted(bg_bt, alpha_bt, og, 0, 0.0, bg_bt);\n",
    "        cv2.addWeighted(bg_dk, alpha_d, og, 0, 0.0, bg_dk);\n",
    "        \n",
    "        bg_bb = cv2.max(bg_bt, bg_dk)\n",
    "        bg_bd = cv2.max(bg_border, bg_nm) # BG_BORDER\n",
    "        bg_all = cv2.max(bg_bb, bg_bd)\n",
    "        \n",
    "        final = cv2.max(og, bg_all)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cloth_texture(frame):\n",
    "        green_dk_low = np.array([0, 115, 70], np.uint8)\n",
    "        green_dk_upp = np.array([80, 255, 150], np.uint8)\n",
    "        green_nm_low = np.array([0, 115, 150], np.uint8)\n",
    "        green_nm_upp = np.array([80, 255, 200], np.uint8)\n",
    "        green_bt_low = np.array([0, 115, 200], np.uint8)\n",
    "        green_bt_upp = np.array([80, 255, 255], np.uint8)\n",
    "\n",
    "        hsv = convert_bgr_to_hsv(frame)\n",
    "        mask_dk = threshold_frame(hsv, green_dk_low, green_dk_upp)\n",
    "        mask_nm = threshold_frame(hsv, green_nm_low, green_nm_upp)\n",
    "        mask_bt = threshold_frame(hsv, green_bt_low, green_bt_upp)\n",
    "        \n",
    "        mask = or_frames(or_frames(mask_bt, mask_nm), mask_dk)\n",
    "        \n",
    "        kernel_ones = np.ones((3,3),np.uint8)\n",
    "        kernel_gauss = cv2.getGaussianKernel(5, 3)\n",
    "        \n",
    "        mask_dil = cv2.erode(mask, kernel_ones, iterations = 1)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_ones, iterations = 5)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_gauss, iterations = 5)\n",
    "        mask_border = cv2.bitwise_and(invert_frame(mask), mask_dil)\n",
    "        mask_border = cv2.GaussianBlur(mask_border, (5,5), 0)\n",
    "        mask_inv = invert_frame(mask_dil)\n",
    "        \n",
    "        og = mask_frame(frame, mask_inv)\n",
    "        \n",
    "        # Get \"see-through\" background\n",
    "        bg_bt = mask_frame(bg, mask_bt)\n",
    "        bg_nm = mask_frame(bg, mask_nm)\n",
    "        bg_dk = mask_frame(bg, mask_dk)\n",
    "        bg_border = mask_frame(bg, mask_border)\n",
    "        \n",
    "        background = mask_frame(bg, mask)\n",
    "        \n",
    "        alpha_border = 0.9\n",
    "        alpha_nm = 0.89\n",
    "        \n",
    "        alpha_bt = 0.87\n",
    "        alpha_d = 0.75\n",
    "        \n",
    "        cv2.addWeighted(bg_border, alpha_border, og, 0, 0.0, bg_border);\n",
    "        cv2.addWeighted(bg_nm, alpha_nm, og, 0, 0.0, bg_nm);\n",
    "        cv2.addWeighted(bg_bt, alpha_bt, og, 0, 0.0, bg_bt);\n",
    "        cv2.addWeighted(bg_dk, alpha_d, og, 0, 0.0, bg_dk);\n",
    "        \n",
    "        bg_bb = cv2.max(bg_bt, bg_dk)\n",
    "        bg_bd = cv2.max(bg_border, bg_nm)\n",
    "        bg_all = cv2.max(bg_bb, bg_bd)\n",
    "        \n",
    "        final = cv2.max(og, bg_all)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cloth_texture_2(frame):\n",
    "        bg = cv2.imread(PATH_BG_2)\n",
    "        \n",
    "        green_dk_low = np.array([0, 115, 70], np.uint8)\n",
    "        green_dk_upp = np.array([80, 255, 150], np.uint8)\n",
    "        green_nm_low = np.array([0, 115, 150], np.uint8)\n",
    "        green_nm_upp = np.array([80, 255, 200], np.uint8)\n",
    "        green_bt_low = np.array([0, 115, 200], np.uint8)\n",
    "        green_bt_upp = np.array([80, 255, 255], np.uint8)\n",
    "\n",
    "        hsv = convert_bgr_to_hsv(frame)\n",
    "        mask_dk = threshold_frame(hsv, green_dk_low, green_dk_upp)\n",
    "        mask_nm = threshold_frame(hsv, green_nm_low, green_nm_upp)\n",
    "        mask_bt = threshold_frame(hsv, green_bt_low, green_bt_upp)\n",
    "        \n",
    "        mask = or_frames(or_frames(mask_bt, mask_nm), mask_dk)\n",
    "        \n",
    "        kernel_ones = np.ones((3,3),np.uint8)\n",
    "        kernel_gauss = cv2.getGaussianKernel(5, 3)\n",
    "        \n",
    "        mask_dil = cv2.erode(mask, kernel_ones, iterations = 1)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_ones, iterations = 5)\n",
    "        mask_dil = cv2.dilate(mask_dil, kernel_gauss, iterations = 5)\n",
    "        mask_border = cv2.bitwise_and(invert_frame(mask), mask_dil)\n",
    "        mask_border = cv2.GaussianBlur(mask_border, (5,5), 0)\n",
    "        mask_inv = invert_frame(mask_dil)\n",
    "        \n",
    "        og = mask_frame(frame, mask_inv)\n",
    "        \n",
    "        # Get \"see-through\" background\n",
    "        bg_bt = mask_frame(bg, mask_bt)\n",
    "        bg_nm = mask_frame(bg, mask_nm)\n",
    "        bg_dk = mask_frame(bg, mask_dk)\n",
    "        bg_border = mask_frame(bg, mask_border)\n",
    "        \n",
    "        background = mask_frame(bg, mask)\n",
    "        \n",
    "        alpha_border = 0.9\n",
    "        alpha_nm = 0.89\n",
    "        \n",
    "        alpha_bt = 0.87\n",
    "        alpha_d = 0.75\n",
    "        \n",
    "        cv2.addWeighted(bg_border, alpha_border, og, 0, 0.0, bg_border);\n",
    "        cv2.addWeighted(bg_nm, alpha_nm, og, 0, 0.0, bg_nm);\n",
    "        cv2.addWeighted(bg_bt, alpha_bt, og, 0, 0.0, bg_bt);\n",
    "        cv2.addWeighted(bg_dk, alpha_d, og, 0, 0.0, bg_dk);\n",
    "        \n",
    "        bg_bb = cv2.max(bg_bt, bg_dk)\n",
    "        bg_bd = cv2.max(bg_border, bg_nm)\n",
    "        bg_all = cv2.max(bg_bb, bg_bd)\n",
    "        \n",
    "        final = cv2.max(og, bg_all)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = open_video()\n",
    "\n",
    "if is_save_video:\n",
    "    out = create_video_writer(cap)\n",
    "\n",
    "skip_to_frame(cap, 0)\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        final = process_frame(cap.get(cv2.CAP_PROP_POS_FRAMES), frame)\n",
    "    \n",
    "        # Display the resulting frames\n",
    "        if is_show_scenes:\n",
    "            cv2.namedWindow('Original', cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow('Original', 640, 360)\n",
    "            cv2.imshow('Original', frame)\n",
    "            \n",
    "            cv2.namedWindow('Final', cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow('Final', 640, 360)\n",
    "            cv2.imshow('Final', final)\n",
    " \n",
    "        if is_save_video:\n",
    "            out.write(final)\n",
    "\n",
    "        # Press Q on keyboard to exit\n",
    "        key = cv2.waitKey(25) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop when video ends\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "if is_save_video:\n",
    "    out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
